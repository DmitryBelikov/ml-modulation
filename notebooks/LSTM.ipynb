{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1538a1b8-acd1-4296-a996-ad63b7dcf509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6fc93be-d1c8-4ae8-a4a6-c5e634b66768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "log_dir = Path('logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9725c9c-a8f6-45f1-a520-c9ab5ad40bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ModulatorDataset(Dataset):\n",
    "    def __init__(self, bit_count):\n",
    "        super().__init__()\n",
    "        self.bit_count = bit_count\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 2 ** self.bit_count\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        result = torch.zeros(2 ** self.bit_count)\n",
    "        result[idx] = 1\n",
    "        return result\n",
    "\n",
    "bit_count = 4\n",
    "class_count = 2 ** bit_count\n",
    "dataset = ModulatorDataset(bit_count)\n",
    "dataloader = DataLoader(dataset, batch_size=class_count, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a7a437-8f51-49a1-82be-431fafa78dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyNormalization(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        energy = (x ** 2).sum(axis=1).mean()\n",
    "        return x / energy.sqrt()\n",
    "\n",
    "class AwgnNoise(nn.Module):\n",
    "    def __init__(self, snr):\n",
    "        super().__init__()\n",
    "        self.sigma = np.sqrt(1 / (2 * 10 ** (snr / 10)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + torch.normal(torch.zeros_like(x, device=self.device), \n",
    "                                torch.full_like(x, self.sigma, device=self.device))\n",
    "\n",
    "\n",
    "class ModulatorAutoencoder(pl.LightningModule):\n",
    "    def __init__(self, class_count, encoding_shape, snr):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(class_count, 4 * class_count),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(4 * class_count, encoding_shape),\n",
    "            EntropyNormalization()\n",
    "        )\n",
    "        self.noise = AwgnNoise(snr)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_shape, 4 * class_count),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * class_count, class_count),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.symbol_error_rate = torchmetrics.Accuracy()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        noised = self.noise(encoded)\n",
    "        return self.decoder(noised)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        decoded = self(batch)\n",
    "        prediction = decoded.argmax(-1)\n",
    "        true_classes = batch.argmax(-1)\n",
    "        loss = self.loss_function(decoded, batch)\n",
    "        ser = self.symbol_error_rate(prediction, true_classes)\n",
    "        self.log('ser', ser, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log('loss', loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.005)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.3, patience=1000, threshold=0.005, min_lr=1e-5)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'scheduler': scheduler,\n",
    "            'monitor': 'loss'\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modulation",
   "language": "python",
   "name": "modulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
